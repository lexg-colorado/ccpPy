# C/C++ to Python Translator Configuration

# Project settings
project:
  # Project name (for logging and output organization)
  name: "c-translator"
  # Optional: Load settings from a profile (profiles/*.yaml)
  # Profile settings override config settings when specified
  profile: null

# Source code paths
source:
  # Path to C/C++ source code
  source_path: "/home/lex/Python/htop"
  # Source language: "c", "cpp", or "auto" (detect from extensions)
  language: "c"
  # Specific subdirectories to focus on (empty = all)
  include_dirs: []
  # File patterns to exclude
  exclude_patterns:
    - "*.o"
    - "*.a"
    - "build/*"
    - "*.autom4te.cache"

# Output paths (relative to project root)
output:
  data_dir: "data"
  ast_cache: "data/ast_cache"
  graphs: "data/graphs"
  embeddings: "data/embeddings"
  translation_memory: "data/translation_memory"
  python_output: "output/python_output"

# Parsing configuration
parsing:
  # File extensions to parse (by language)
  extensions:
    c:
      - ".c"
      - ".h"
    cpp:
      - ".cpp"
      - ".cxx"
      - ".cc"
      - ".hpp"
      - ".hxx"
      - ".hh"
  # Default language for .h files: "c" or "cpp"
  header_language: "c"
  # Maximum file size to parse (in MB)
  max_file_size_mb: 10

# C++ specific settings
cpp:
  # Parse C++ template definitions
  parse_templates: true
  # Parse namespace declarations
  parse_namespaces: true
  # Include C++ standard library mappings
  include_std_library: false

# Dependency graph settings
dependency_graph:
  # Include system headers in graph?
  include_system_headers: false
  # Maximum depth for dependency traversal
  max_depth: 10

# Embedding configuration
embeddings:
  # Model for generating embeddings
  # Options: "sentence-transformers", "tfidf"
  model_type: "sentence-transformers"
  model_name: "all-MiniLM-L6-v2"
  # Chunk size for code units
  chunk_size: 512
  # Batch size for embedding generation
  batch_size: 32

# Vector store settings
vector_store:
  # Type: "faiss", "simple"
  type: "faiss"
  # Similarity metric: "cosine", "euclidean"
  similarity_metric: "cosine"
  # Number of results to retrieve
  top_k: 5

# LLM configuration
llm:
  # Backend provider: "ollama", "openai", "anthropic"
  backend: "ollama"

  # Ollama settings (used when backend: "ollama")
  ollama:
    base_url: "http://localhost:11434"
    model: "qwen3:4b"

  # OpenAI settings (used when backend: "openai")
  openai:
    # API key loaded from OPENAI_API_KEY environment variable
    model: "gpt-4"

  # Anthropic settings (used when backend: "anthropic")
  anthropic:
    # API key loaded from ANTHROPIC_API_KEY environment variable
    model: "claude-3-sonnet-20240229"

  # Generation parameters (apply to all backends)
  temperature: 0.2
  top_p: 0.9
  max_tokens: 4096
  # Context window management
  max_context_tokens: 8192

# Translation settings
translation:
  # Start with leaf nodes (no dependencies)
  start_with_leaves: true
  # Maximum number of iterations for a single translation
  max_iterations: 3
  # Include similar code examples in context
  include_examples: true
  # Number of similar examples to include
  num_examples: 3

  # Python output style preferences
  python_style:
    # Generate type hints in output
    use_type_hints: true
    # Use dataclasses for C structs
    use_dataclasses: true
    # Docstring style: "google", "numpy", "sphinx"
    docstring_style: "google"
    # Maximum line length (for formatting)
    line_length: 88
    # Target Python version (for compatibility)
    python_version: "3.9"

# Library mappings configuration
library_mappings:
  # Enable library mapping system
  enabled: true
  # Built-in mappers to use
  builtin_mappers:
    - "stdlib"      # C standard library
    - "ncurses"     # ncurses -> curses
    - "pthread"     # pthread -> threading
  # Paths to custom mapping YAML files (relative to project root)
  custom_mappings: []

# Validation settings
validation:
  # Run syntax validation
  check_syntax: true
  # Run type checking (mypy)
  check_types: true
  # Run linting (pylint)
  run_linting: false
  # Minimum code quality score (0-10)
  min_quality_score: 6.0

# Logging configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  file: "logs/translator.log"
  # Log to console as well
  console: true

# Performance settings
performance:
  # Use multiprocessing for parsing
  parallel_parsing: true
  # Number of worker processes (null = CPU count)
  num_workers: null
  # Cache parsed ASTs
  cache_asts: true

# Experimental features
experimental:
  # Use few-shot learning with examples
  few_shot_translation: true
  # Attempt to preserve code comments
  preserve_comments: true
